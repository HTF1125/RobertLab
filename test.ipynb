{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Optional, Callable, Dict, List\n",
    "from functools import partial\n",
    "from scipy.optimize import minimize\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class OptMetrics:\n",
    "    \"\"\"portfolio optimizer metrics\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def expected_return(\n",
    "        weights: np.ndarray,\n",
    "        expected_returns: np.ndarray,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Portfolio expected return.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): weight of assets.\n",
    "            expected_returns (np.ndarray): expected return of assets.\n",
    "\n",
    "        Returns:\n",
    "            float: portfolio expected return.\n",
    "        \"\"\"\n",
    "        return np.dot(weights, expected_returns)\n",
    "\n",
    "    @staticmethod\n",
    "    def expected_variance(\n",
    "        weights: np.ndarray,\n",
    "        covariance_matrix: np.ndarray,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Portfolio expected variance.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): weight of assets.\n",
    "            covariance_matrix (np.ndarray): covariance matrix of assets.\n",
    "\n",
    "        Returns:\n",
    "            float: portfolio expected variance.\n",
    "        \"\"\"\n",
    "        return np.linalg.multi_dot((weights, covariance_matrix, weights))\n",
    "\n",
    "    def expected_volatility(\n",
    "        self, weights: np.ndarray, covariance_matrix: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Portfolio expected volatility.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): weight of assets.\n",
    "            covariance_matrix (np.ndarray): covariance matrix of assets.\n",
    "\n",
    "        Returns:\n",
    "            float: portfolio expected volatility.\n",
    "        \"\"\"\n",
    "        return np.sqrt(\n",
    "            self.expected_variance(weights=weights, covariance_matrix=covariance_matrix)\n",
    "        )\n",
    "\n",
    "    def expected_sharpe(\n",
    "        self,\n",
    "        weights: np.ndarray,\n",
    "        expected_returns: np.ndarray,\n",
    "        covariance_matrix: np.ndarray,\n",
    "        risk_free: float = 0.0,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Portfolio expected sharpe ratio.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): weight of assets.\n",
    "            expected_returns (np.ndarray): expected return of assets.\n",
    "            covariance_matrix (np.ndarray): covariance matrix of assets.\n",
    "\n",
    "        Returns:\n",
    "            float: portfolio expected sharpe ratio.\n",
    "        \"\"\"\n",
    "        ret = self.expected_return(weights=weights, expected_returns=expected_returns)\n",
    "        std = self.expected_volatility(\n",
    "            weights=weights, covariance_matrix=covariance_matrix\n",
    "        )\n",
    "        return (ret - risk_free) / std\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_norm(vals: np.ndarray, gamma: float = 1) -> float:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            vals (np.ndarray): _description_\n",
    "            gamma (float, optional): _description_. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            float: _description_\n",
    "        \"\"\"\n",
    "        return np.abs(vals).sum() * gamma\n",
    "\n",
    "    @staticmethod\n",
    "    def l2_norm(vals: np.ndarray, gamma: float = 1) -> float:\n",
    "        \"\"\"\n",
    "        L2 regularization.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): asset weight in the portfolio.\n",
    "            gamma (float, optional): L2 regularisation parameter. Defaults to 1.\n",
    "                Increase if you want more non-negligible weight.\n",
    "\n",
    "        Returns:\n",
    "            float: L2 regularization.\n",
    "        \"\"\"\n",
    "        return np.sum(np.square(vals)) * gamma\n",
    "\n",
    "    @staticmethod\n",
    "    def exante_tracking_error(\n",
    "        weights: np.ndarray, weights_bm: np.ndarray, covariance_matrix: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the ex-ante tracking error.\n",
    "\n",
    "        Maths:\n",
    "            formula here.\n",
    "\n",
    "        Args:\n",
    "            weight (np.ndarray): asset weight in the portfolio.\n",
    "            weight_benchmark (np.ndarray): benchmarket weight of the portfolio.\n",
    "            covaraince_matrix (np.ndarray): asset covariance matrix.\n",
    "\n",
    "        Returns:\n",
    "            float: ex-ante tracking error.\n",
    "        \"\"\"\n",
    "        rel_weight = np.subtract(weights, weights_bm)\n",
    "        tracking_variance = np.dot(np.dot(rel_weight, covariance_matrix), rel_weight)\n",
    "        tracking_error = np.sqrt(tracking_variance)\n",
    "        return tracking_error\n",
    "\n",
    "    @staticmethod\n",
    "    def expost_tracking_error(\n",
    "        weights: np.ndarray,\n",
    "        pri_returns_assets: np.ndarray,\n",
    "        pri_returns_bm: np.ndarray,\n",
    "    ) -> float:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            weights (np.ndarray): _description_\n",
    "            pri_returns_assets (np.ndarray): _description_\n",
    "            pri_returns_benchmark (np.ndarray): _description_\n",
    "\n",
    "        Returns:\n",
    "            float: _description_\n",
    "        \"\"\"\n",
    "        rel_return = np.dot(pri_returns_assets, weights) - pri_returns_bm\n",
    "        mean = np.sum(rel_return) / len(rel_return)\n",
    "        return np.sum(np.square(rel_return - mean))\n",
    "\n",
    "    def risk_contributions(\n",
    "        self,\n",
    "        weights: np.ndarray,\n",
    "        covariance_matrix: np.ndarray,\n",
    "        sub_covariance_matrix_idx: Optional[List] = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"risk contributions\"\"\"\n",
    "        volatility = self.expected_volatility(\n",
    "            weights=weights, covariance_matrix=covariance_matrix\n",
    "        )\n",
    "        if sub_covariance_matrix_idx:\n",
    "            sub_covariance_matrix = covariance_matrix.copy()\n",
    "            for i, row in enumerate(covariance_matrix):\n",
    "                for j, val in enumerate(row):\n",
    "                    if (\n",
    "                        i not in sub_covariance_matrix_idx\n",
    "                        and j not in sub_covariance_matrix_idx\n",
    "                    ):\n",
    "                        sub_covariance_matrix[i, j] = 0\n",
    "            return np.dot(sub_covariance_matrix, weights) * weights / volatility\n",
    "\n",
    "        return np.dot(covariance_matrix, weights) * weights / volatility\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    \"\"\"portfolio optimizer\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        expected_returns: Optional[pd.Series] = None,\n",
    "        covariance_matrix: Optional[pd.DataFrame] = None,\n",
    "        risk_free: float = 0.0,\n",
    "        prices_assets: Optional[pd.DataFrame] = None,\n",
    "        prices_bm: Optional[pd.Series] = None,\n",
    "        weights_bm: Optional[pd.Series] = None,\n",
    "        min_weight: float = 0.0,\n",
    "        max_weight: float = 1.0,\n",
    "        sum_weight: float = 1.0,\n",
    "        min_return: Optional[float] = None,\n",
    "        max_return: Optional[float] = None,\n",
    "        min_volatility: Optional[float] = None,\n",
    "        max_volatility: Optional[float] = None,\n",
    "        active_weight: Optional[float] = None,\n",
    "        exante_tracking_error: Optional[float] = None,\n",
    "        expost_tracking_error: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"initialization\"\"\"\n",
    "\n",
    "        if expected_returns is not None:\n",
    "            self.expected_returns = expected_returns\n",
    "            self.assets = self.expected_returns.index\n",
    "\n",
    "        if covariance_matrix is not None:\n",
    "            self.covariance_matrix = covariance_matrix\n",
    "\n",
    "        self.expected_returns = expected_returns\n",
    "        self.covariance_matrix = covariance_matrix\n",
    "        self.prices_assets = prices_assets\n",
    "        self.risk_free = risk_free\n",
    "        self.prices_bm = prices_bm\n",
    "        self.weights_bm = weights_bm\n",
    "        self.constraints: List = []\n",
    "        self.metrics: OptMetrics = OptMetrics()\n",
    "\n",
    "        self.set_min_weight(min_weight=min_weight)\n",
    "        self.set_max_weight(max_weight=max_weight)\n",
    "        self.set_sum_weight(sum_weight=sum_weight)\n",
    "\n",
    "        if min_return:\n",
    "            self.set_min_return(min_return=min_return)\n",
    "\n",
    "        if max_return:\n",
    "            self.set_max_return(max_return=max_return)\n",
    "\n",
    "        if min_volatility:\n",
    "            self.set_min_volatility(min_volatility=min_volatility)\n",
    "\n",
    "        if max_volatility:\n",
    "            self.set_max_volatility(max_volatility=max_volatility)\n",
    "\n",
    "        if active_weight:\n",
    "            self.set_max_active_weight(active_weight=active_weight)\n",
    "\n",
    "        if exante_tracking_error:\n",
    "            self.set_exante_tracking_error(exante_tracking_error=exante_tracking_error)\n",
    "\n",
    "        if expost_tracking_error:\n",
    "            self.set_max_expost_tracking_error(\n",
    "                expost_tracking_error=expost_tracking_error\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def expected_returns(self) -> pd.Series:\n",
    "        \"\"\"expected_returns\"\"\"\n",
    "        return self._expected_returns\n",
    "\n",
    "    @expected_returns.setter\n",
    "    def expected_returns(self, expected_returns: Optional[pd.Series] = None) -> None:\n",
    "        self._expected_returns = expected_returns\n",
    "        if expected_returns is not None:\n",
    "            self.assets = self.expected_returns.index\n",
    "\n",
    "    @property\n",
    "    def covariance_matrix(self) -> pd.DataFrame:\n",
    "        \"\"\"covariance_matrix\"\"\"\n",
    "        return self._covariance_matrix\n",
    "\n",
    "    @covariance_matrix.setter\n",
    "    def covariance_matrix(\n",
    "        self, covariance_matrix: Optional[pd.DataFrame] = None\n",
    "    ) -> None:\n",
    "        self._covariance_matrix = covariance_matrix\n",
    "        if covariance_matrix is not None:\n",
    "            self.assets = self.covariance_matrix.index\n",
    "            self.assets = self.covariance_matrix.columns\n",
    "\n",
    "    @property\n",
    "    def prices_assets(self) -> pd.DataFrame:\n",
    "        \"\"\"prices_assets\"\"\"\n",
    "        return self._prices_assets\n",
    "\n",
    "    @prices_assets.setter\n",
    "    def prices_assets(self, prices_assets: Optional[pd.DataFrame] = None) -> None:\n",
    "        self._prices_assets = prices_assets\n",
    "        if prices_assets is not None:\n",
    "            self.assets = self.prices_assets.columns\n",
    "\n",
    "    @property\n",
    "    def assets(self) -> pd.Index:\n",
    "        \"\"\"assets\"\"\"\n",
    "        try:\n",
    "            return self._assets\n",
    "        except AttributeError:\n",
    "            return None\n",
    "\n",
    "    @assets.setter\n",
    "    def assets(self, assets: pd.Index) -> None:\n",
    "        \"\"\"assets setter\"\"\"\n",
    "\n",
    "        if self.assets is not None:\n",
    "            assert self.assets.equals(assets)\n",
    "            return\n",
    "        self._assets = assets\n",
    "\n",
    "    @property\n",
    "    def num_asset(self) -> int:\n",
    "        \"\"\"return number of asset\"\"\"\n",
    "        return len(self.assets)\n",
    "\n",
    "    def set_min_weight(self, min_weight: float = 0.0) -> None:\n",
    "        \"\"\"set minimum weights constraint\"\"\"\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: w - min_weight,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_weight(self, max_weight: float = 1.0) -> None:\n",
    "        \"\"\"set maximum weights constraint\"\"\"\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: max_weight - w,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_sum_weight(self, sum_weight: float = 1.0) -> None:\n",
    "        \"\"\"set summation weights constriant\"\"\"\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"eq\",\n",
    "                \"fun\": lambda w: np.sum(w) - sum_weight,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_min_return(self, min_return: float = 0.05) -> None:\n",
    "        \"\"\"set minimum return constraint\"\"\"\n",
    "        if self.expected_returns is None:\n",
    "            warnings.warn(\"unable to set minimum return constraint.\")\n",
    "            warnings.warn(\"expected returns is null.\")\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: self.metrics.expected_return(\n",
    "                    weights=w, expected_returns=self.expected_returns.values\n",
    "                )\n",
    "                - min_return,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_return(self, max_return: float = 0.05) -> None:\n",
    "        \"\"\"set maximum return constraint\"\"\"\n",
    "        if self.expected_returns is None:\n",
    "            warnings.warn(\"unable to set maximum return constraint.\")\n",
    "            warnings.warn(\"expected returns is null.\")\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: max_return\n",
    "                - self.metrics.expected_return(\n",
    "                    weights=w, expected_returns=self.expected_returns.values\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_min_volatility(self, min_volatility: float = 0.05) -> None:\n",
    "        \"\"\"set minimum volatility constraint\"\"\"\n",
    "        if self.expected_returns is None:\n",
    "            warnings.warn(\"unable to set minimum volatility constraint.\")\n",
    "            warnings.warn(\"expected returns is null.\")\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: self.metrics.expected_volatility(\n",
    "                    weights=w, covariance_matrix=self.covariance_matrix.values\n",
    "                )\n",
    "                - min_volatility,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_volatility(self, max_volatility: float = 0.05) -> None:\n",
    "        \"\"\"set maximum volatility constraint\"\"\"\n",
    "        if self.expected_returns is None:\n",
    "            warnings.warn(\"unable to set maximum volatility constraint.\")\n",
    "            warnings.warn(\"expected returns is null.\")\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: max_volatility\n",
    "                - self.metrics.expected_volatility(\n",
    "                    weights=w, covariance_matrix=self.covariance_matrix.values\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_active_weight(self, active_weight: float = 0.10) -> None:\n",
    "        \"\"\"set maximum active weight against benchmark\"\"\"\n",
    "        if self.weights_bm is None:\n",
    "            warnings.warn(\"unable to set maximum active weight constraint.\")\n",
    "            warnings.warn(\"benchmark weights is null.\")\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: active_weight\n",
    "                - np.sum(np.abs(w - self.weights_bm.values)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_exante_tracking_error(\n",
    "        self, max_exante_tracking_error: float = 0.02\n",
    "    ) -> None:\n",
    "        \"\"\"set maximum exante tracking error constraint\"\"\"\n",
    "\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: max_exante_tracking_error\n",
    "                - self.metrics.exante_tracking_error(\n",
    "                    weights=w,\n",
    "                    weights_bm=self.weights_bm.values,\n",
    "                    covariance_matrix=self.covariance_matrix.values,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def set_max_expost_tracking_error(\n",
    "        self, max_expost_tracking_error: float = 0.02\n",
    "    ) -> None:\n",
    "        \"\"\"set maximum expost tracking error constraint\"\"\"\n",
    "\n",
    "        itx = self.prices_assets.dropna().index.intersection(\n",
    "            self.prices_bm.dropna().index\n",
    "        )\n",
    "\n",
    "        pri_returns_assets = self.prices_assets.loc[itx].pct_change().fillna(0)\n",
    "        pri_returns_bm = self.prices_bm.loc[itx].pct_change().fillna(0)\n",
    "\n",
    "        self.constraints.append(\n",
    "            {\n",
    "                \"type\": \"ineq\",\n",
    "                \"fun\": lambda w: max_expost_tracking_error\n",
    "                - self.metrics.expost_tracking_error(\n",
    "                    weights=w,\n",
    "                    pri_returns_assets=pri_returns_assets.values,\n",
    "                    pri_returns_bm=pri_returns_bm.values,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def solve(\n",
    "        self, objective: Callable, extra_constraints: Optional[List[Dict]] = None\n",
    "    ) -> Optional[pd.Series]:\n",
    "        constraints = self.constraints.copy()\n",
    "        if extra_constraints:\n",
    "            constraints.extend(extra_constraints)\n",
    "        problem = minimize(\n",
    "            fun=objective,\n",
    "            method=\"SLSQP\",\n",
    "            constraints=constraints,\n",
    "            x0=np.ones(shape=self.num_asset) / self.num_asset,\n",
    "        )\n",
    "\n",
    "        if problem.success:\n",
    "            return pd.Series(data=problem.x, index=self.assets, name=\"weights\").round(6)\n",
    "        return None\n",
    "\n",
    "    def maximized_return(self) -> Optional[pd.Series]:\n",
    "        \"\"\"calculate max return weights\"\"\"\n",
    "        return self.solve(\n",
    "            objective=partial(\n",
    "                self.metrics.expected_return,\n",
    "                expected_returns=self.expected_returns.values * -1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def minimized_volatility(self) -> Optional[pd.Series]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            Optional[pd.Series]: _description_\n",
    "        \"\"\"\n",
    "        return self.solve(\n",
    "            objective=partial(\n",
    "                self.metrics.expected_volatility,\n",
    "                covariance_matrix=self.covariance_matrix.values,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def maximized_sharpe_ratio(self) -> Optional[pd.Series]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            Optional[pd.Series]: _description_\n",
    "        \"\"\"\n",
    "        return self.solve(\n",
    "            objective=partial(\n",
    "                self.metrics.expected_sharpe,\n",
    "                expected_returns=self.expected_returns.values,\n",
    "                covariance_matrix=self.covariance_matrix.values,\n",
    "                risk_free=self.risk_free,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def hierarchical_risk_parity(self) -> Optional[pd.Series]:\n",
    "        \"\"\"calculate herc weights\"\"\"\n",
    "        corr = cov_to_corr(self.covariance_matrix.values)\n",
    "        dist = np.sqrt((1 - corr).round(5) / 2)\n",
    "        clusters = linkage(squareform(dist), method=\"single\")\n",
    "        cluster_sets = [\n",
    "            (\n",
    "                get_cluster_assets(clusters, cluster[0], self.num_asset),\n",
    "                get_cluster_assets(clusters, cluster[1], self.num_asset),\n",
    "            )\n",
    "            for cluster in clusters\n",
    "        ]\n",
    "        \n",
    "\n",
    "        return self.solve(\n",
    "            objective=lambda w: self.metrics.l2_norm(\n",
    "                np.array(\n",
    "                    [\n",
    "                        np.sum(\n",
    "                            self.metrics.risk_contributions(\n",
    "                                weights=w,\n",
    "                                covariance_matrix=covariance_matrix.values,\n",
    "                                sub_covariance_matrix_idx=left_idx,\n",
    "                            )\n",
    "                        )\n",
    "                        - np.sum(\n",
    "                            self.metrics.risk_contributions(\n",
    "                                weights=w,\n",
    "                                covariance_matrix=covariance_matrix.values,\n",
    "                                sub_covariance_matrix_idx=right_idx,\n",
    "                            )\n",
    "                        )\n",
    "                        for left_idx, right_idx in cluster_sets\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def risk_parity(self, budgets: Optional[np.ndarray] = None) -> Optional[pd.Series]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            Optional[pd.Series]: _description_\n",
    "        \"\"\"\n",
    "        if budgets is None:\n",
    "            budgets = np.ones(self.num_asset) / self.num_asset\n",
    "        return self.solve(\n",
    "            objective=lambda w: self.metrics.l2_norm(\n",
    "                np.subtract(\n",
    "                    self.metrics.risk_contributions(\n",
    "                        weights=w, covariance_matrix=self.covariance_matrix.values\n",
    "                    ),\n",
    "                    np.multiply(\n",
    "                        budgets,\n",
    "                        self.metrics.expected_volatility(\n",
    "                            weights=w, covariance_matrix=self.covariance_matrix.values\n",
    "                        ),\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def inverse_variance(self) -> Optional[pd.Series]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            Optional[pd.Series]: _description_\n",
    "        \"\"\"\n",
    "        inv_var_weights = 1 / np.diag(covariance_matrix)\n",
    "        inv_var_weights /= inv_var_weights.sum()\n",
    "        return self.solve(\n",
    "            objective=lambda w: self.metrics.l2_norm(np.subtract(w, inv_var_weights))\n",
    "        )\n",
    "\n",
    "\n",
    "def cov_to_corr(covariance_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"correlation matrix from covariance matrix\"\"\"\n",
    "    vol = np.sqrt(np.diag(covariance_matrix))\n",
    "    corr = np.divide(covariance_matrix, np.outer(vol, vol))\n",
    "    corr[corr < -1], corr[corr > 1] = -1, 1\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_cluster_assets(clusters, node, num_assets) -> List:\n",
    "    if node < num_assets:\n",
    "        return [int(node)]\n",
    "    row = clusters[int(node - num_assets)]\n",
    "    return get_cluster_assets(clusters, row[0], num_assets) + get_cluster_assets(\n",
    "        clusters, row[1], num_assets\n",
    "    )\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "prices = yf.download(\"SPY, QQQ, IWV, MTUM, QUAL, VLUE, IVV\")[\"Adj Close\"].dropna()\n",
    "expected_returns = prices.pct_change().fillna(0).mean() * 252\n",
    "covariance_matrix = prices.pct_change().fillna(0).cov() * (252)\n",
    "\n",
    "optimizer = Optimizer(\n",
    "    expected_returns=expected_returns,\n",
    "    covariance_matrix=covariance_matrix,\n",
    ")\n",
    "optimizer.hierarchical_risk_parity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import riskfolio as rf\n",
    "\n",
    "port = rf.Portfolio(returns=prices.pct_change().fillna(0).dropna())\n",
    "port.optimization(model=\"HERC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "source": [
    "def quasi_diagnalization(clusters, num_assets, curr_index):\n",
    "    \"\"\"Rearrange the assets to reorder them according to hierarchical tree clustering order\"\"\"\n",
    "\n",
    "    if curr_index < num_assets:\n",
    "        return [curr_index]\n",
    "\n",
    "    left = int(clusters[curr_index - num_assets, 0])\n",
    "    right = int(clusters[curr_index - num_assets, 1])\n",
    "\n",
    "    return quasi_diagnalization(clusters, num_assets, left) + quasi_diagnalization(\n",
    "        clusters, num_assets, right\n",
    "    )\n",
    "\n",
    "from scipy.cluster.hierarchy import to_tree, linkage, dendrogram\n",
    "\n",
    "prices = yf.download(\"SPY, QQQ, IWV, MTUM, QUAL, VLUE, IVV\")[\"Adj Close\"].dropna()\n",
    "expected_returns = prices.pct_change().fillna(0).mean() * 252\n",
    "covariance_matrix = prices.pct_change().fillna(0).cov() * (252)\n",
    "corr = cov_to_corr(covariance_matrix.values)\n",
    "dist = np.sqrt((1 - corr).round(5) / 2)\n",
    "clusters = linkage(squareform(dist), method=\"single\")\n",
    "sorted_index = list(to_tree(clusters, rd=False).pre_order())\n",
    "# clustered_assets = [[self.assets[x] for x in sorted_index]]\n",
    "# print(sorted_index)\n",
    "# dendrogram(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([2, 6, 3], [4, 1, 0, 5]), [([2], [6, 3]), None, None], [([4, 1], [0, 5]), None, None]]\n"
     ]
    }
   ],
   "source": [
    "def bisect(sorted_index):\n",
    "    \n",
    "    if len(sorted_index) < 3:\n",
    "        return None\n",
    "    \n",
    "    num = len(sorted_index)\n",
    "    bis = int(num/2)\n",
    "    \n",
    "    left = sorted_index[0: bis]\n",
    "    right = sorted_index[bis:]\n",
    "    return [(left, right), bisect(left), bisect(right)]\n",
    "print(bisect(sorted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index\n",
    "def divide_chunks(l, n):\n",
    "     \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "for i in range(len(sorted_index) - 2, 0, -1):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    print(list(divide_chunks(sorted_index, i)))\n",
    "    # print(list(divide_chunks(sorted_index, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_variance_weights(covariance_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"calculate weights of inverse variance. (tot weights = 100%)\n",
    "\n",
    "    Args:\n",
    "        covariance_matrix (np.ndarray): _description_\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: weights of\n",
    "    \"\"\"\n",
    "    inv_var_weights = 1 / np.diag(covariance_matrix)\n",
    "    inv_var_weights /= inv_var_weights.sum()\n",
    "    return inv_var_weights\n",
    "\n",
    "inverse_variance_weights(covariance_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_excel(\"database.xlsx\", sheet_name=\"tb_meta\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# for id, m in meta.iterrows():\n",
    "#     tic = yf.Ticker(m.ticker)\n",
    "#     ff = tic.isin\n",
    "#     print(ff)\n",
    "\n",
    "for id, row in meta.iterrows():\n",
    "    print(row.ticker)\n",
    "    if row.__ticker.endswith(\".KS\"):\n",
    "        continue\n",
    "\n",
    "    t = yf.Ticker(row.ticker)\n",
    "\n",
    "    hist = t.history(period=\"1y\")\n",
    "    try:\n",
    "        splits = hist[\"Stock Splits\"]\n",
    "\n",
    "        test = (splits != 0).any()\n",
    "        if test:\n",
    "            print(\"Has splits\")\n",
    "            print(row.ticker)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "t = yf.Ticker(\"HYMB\")\n",
    "hist = t.history(period=\"1y\")\n",
    "splits = hist[\"Stock Splits\"]\n",
    "splits = splits[splits != 0]\n",
    "splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" base strategy class \"\"\"\n",
    "\n",
    "import warnings\n",
    "from typing import Any, List, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Account:\n",
    "    \"\"\"strategy account\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.date: List = []\n",
    "        self.value: List = []\n",
    "        self.weights: List[Dict] = []\n",
    "        self.reb_weights: List[Dict] = []\n",
    "        self.trade_weights: List[Dict] = []\n",
    "\n",
    "\n",
    "class BaseStrategy:\n",
    "    \"\"\"\n",
    "    BaseStrategy class is an algorithmic trading strategy that sequentially allocates capital among\n",
    "    group of assets based on pre-defined allocatioin method.\n",
    "\n",
    "    BaseStrategy shall be the parent class for all investment strategies with period-wise\n",
    "    rebalancing scheme.\n",
    "\n",
    "    Using this class requires following pre-defined methods:\n",
    "    1. rebalance(self, price_asset, date, **kwargs):\n",
    "        the method shall be in charge of calculating new weights based on prices\n",
    "        that are avaiable.\n",
    "    2. monitor (self, ...):\n",
    "        the method shall be in charge of monitoring the strategy status, and if\n",
    "        necessary call the rebalance method to re-calculate weights. aka irregular rebalancing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        price_asset: pd.DataFrame,\n",
    "        frequency: str = \"M\",\n",
    "        min_assets: int = 2,\n",
    "        min_periods: int = 2,\n",
    "        investment: float = 1000.0,\n",
    "        commission: int = 0,\n",
    "        currency: str = \"KRW\",\n",
    "        name: str = \"strategy\",\n",
    "        account: Optional[Account] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.price_asset: pd.DataFrame = self.check_price_df(price_asset)\n",
    "        self.frequency: str = frequency\n",
    "        self.min_assets: int = min_assets\n",
    "        self.min_periods: int = min_periods\n",
    "        self.name: str = name\n",
    "        self.commission = commission\n",
    "        self.currency = currency\n",
    "\n",
    "        # account information\n",
    "        self.idx: int = 0\n",
    "        self.date: Any = None\n",
    "        self.value: float = investment\n",
    "        self.weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.reb_weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.trade_weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.account: Account = account or Account()\n",
    "\n",
    "    ################################################################################################\n",
    "    @property\n",
    "    def value_df(self):\n",
    "        \"\"\"values dataframe\"\"\"\n",
    "        return pd.DataFrame(\n",
    "            data=self.account.value, index=self.account.date, columns=[\"value\"]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.weights, index=self.account.date)\n",
    "\n",
    "    @property\n",
    "    def reb_weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.reb_weights, index=self.account.date)\n",
    "\n",
    "    @property\n",
    "    def trade_weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.trade_weights, index=self.account.date)\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    def update_book(self) -> None:\n",
    "        \"\"\"update the account value based on the current date\"\"\"\n",
    "        prices = self.price_asset.loc[self.date]\n",
    "        if not self.weights.empty:\n",
    "            print(f\"update book values\")\n",
    "            pre_prices = self.price_asset.iloc[\n",
    "                self.price_asset.index.get_loc(self.date) - 1\n",
    "            ]\n",
    "            capitals = self.weights * self.value\n",
    "            pri_return = prices / pre_prices\n",
    "            new_capitals = capitals * pri_return.loc[capitals.index]\n",
    "            profit_loss = new_capitals - capitals\n",
    "            self.value += profit_loss.sum()\n",
    "            self.weights = new_capitals / self.value\n",
    "\n",
    "        if not self.reb_weights.empty:\n",
    "            print(f\"make re-allocation {self.reb_weights.to_dict()}\")\n",
    "            # reindex to contain the same asset.\n",
    "            union_assets = self.reb_weights.index.union(self.weights.index)\n",
    "            self.weights = self.weights.reindex(union_assets, fill_value=0)\n",
    "            self.reb_weights = self.reb_weights.reindex(union_assets, fill_value=0)\n",
    "            self.trade_weights = self.reb_weights.subtract(self.weights)\n",
    "            trade_capitals = self.value * self.trade_weights\n",
    "            trade_costs = trade_capitals.abs() * self.commission / 10_000\n",
    "            trade_cost = trade_costs.sum()\n",
    "            # update the account metrics.\n",
    "            self.value -= trade_cost\n",
    "            self.weights = self.reb_weights\n",
    "\n",
    "        # do nothing if no account data.\n",
    "        if self.weights.empty and self.reb_weights.empty:\n",
    "            return\n",
    "        # loop through all variables in account history\n",
    "        for name in vars(self.account).keys():\n",
    "            getattr(self.account, name).append(getattr(self, name))\n",
    "        # clear the rebalancing weights.\n",
    "        self.reb_weights = pd.Series(dtype=float)\n",
    "        self.trade_weights = pd.Series(dtype=float)\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    def simulate(self, start: ... = None, end: ... = None) -> ...:\n",
    "        \"\"\"simulate historical strategy perfromance\"\"\"\n",
    "        start = start or self.price_asset.index[0]\n",
    "        end = end or self.price_asset.index[-1]\n",
    "        reb_dates = pd.date_range(start=start, end=end, freq=self.frequency)\n",
    "        for self.date in pd.date_range(start=start, end=end, freq=\"D\"):\n",
    "            print(self.date)\n",
    "            if self.date in self.price_asset.index:\n",
    "                self.update_book()\n",
    "            if self.weights.empty or self.monitor() or self.date in reb_dates:\n",
    "                if not self.reb_weights.empty:\n",
    "                    continue\n",
    "                self.reb_weights = self.allocate(self.date)\n",
    "                print(f\"rebalancing weights: {self.reb_weights.to_dict()}\")\n",
    "        return self\n",
    "\n",
    "    def allocate(self, date: ... = None) -> pd.Series:\n",
    "        \"\"\"allocate weights based on date if date not provided use latest\"\"\"\n",
    "        # pylint: disable=multiple-statements\n",
    "        date = date or self.price_asset.index[-1]\n",
    "        price_slice = self.price_asset.loc[:date].dropna(\n",
    "            thresh=self.min_periods, axis=1\n",
    "        )\n",
    "        if price_slice.empty:\n",
    "            return pd.Series(dtype=float)\n",
    "        reb_weights = self.rebalance(price_asset=price_slice)\n",
    "        if reb_weights is None:\n",
    "            return pd.Series(dtype=float)\n",
    "        return self.clean_weights(reb_weights, decimals=4)\n",
    "\n",
    "    def rebalance(self, price_asset: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Default rebalancing method\"\"\"\n",
    "        asset = price_asset.columns\n",
    "        uniform_weight = np.ones(len(asset))\n",
    "        uniform_weight /= uniform_weight.sum()\n",
    "        weight = pd.Series(index=asset, data=uniform_weight)\n",
    "        return weight\n",
    "\n",
    "    def monitor(self) -> bool:\n",
    "        \"\"\"Default monitoring method.\"\"\"\n",
    "        return False\n",
    "\n",
    "    ################################################################################################\n",
    "    @staticmethod\n",
    "    def check_price_df(price_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Check the price_df.\n",
    "\n",
    "        Args:\n",
    "            price_df (pd.DataFrame): _description_\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if price_df is not pd.DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: price_df\n",
    "        \"\"\"\n",
    "        if not isinstance(price_df, pd.DataFrame):\n",
    "            raise TypeError(\"price_df must be a pd.DataFrame.\")\n",
    "        if not isinstance(price_df.index, pd.DatetimeIndex):\n",
    "            warnings.warn(\"converting price_df's index to pd.DatetimeIndex.\")\n",
    "            price_df.index = pd.to_datetime(price_df.index)\n",
    "        return price_df\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_weights(weights: pd.Series, decimals: int = 4) -> pd.Series:\n",
    "        \"\"\"Clean weights based on the number decimals and maintain the total of weights.\n",
    "\n",
    "        Args:\n",
    "            weights (pd.Series): asset weights.\n",
    "            decimals (int, optional): number of decimals to be rounded for\n",
    "                weight. Defaults to 4.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: clean asset weights.\n",
    "        \"\"\"\n",
    "        # clip weight values by minimum and maximum.\n",
    "        tot_weight = weights.sum().round(4)\n",
    "        weights = weights.round(decimals=decimals)\n",
    "        # repeat round and weight calculation.\n",
    "        for _ in range(10):\n",
    "            weights = weights / weights.sum() * tot_weight\n",
    "            weights = weights.round(decimals=decimals)\n",
    "            if weights.sum() == tot_weight:\n",
    "                return weights\n",
    "        # if residual remains after repeated rounding.\n",
    "        # allocate the the residual weight on the max weight.\n",
    "        residual = tot_weight - weights.sum()\n",
    "        # !!! Error may occur when there are two max weights???\n",
    "        weights[np.argmax(weights)] += np.round(residual, decimals=decimals)\n",
    "        return weights\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "def backtest(allocation_df: pd.DataFrame, price_df: pd.DataFrame) -> BaseStrategy:\n",
    "    \"\"\"provide a backtested strategy.\n",
    "\n",
    "    Args:\n",
    "        allocation_df (pd.DataFrame): allocation dataframe.\n",
    "        price_df (pd.DataFrame): asset price dataframe.\n",
    "\n",
    "    Returns:\n",
    "        BaseStrategy: backtested strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    class Backtest(BaseStrategy):\n",
    "        \"\"\"backtest class\"\"\"\n",
    "\n",
    "        def rebalance(self, price_asset: pd.DataFrame) -> pd.Series:\n",
    "            if self.date in allocation_df.index:\n",
    "                weights = allocation_df.loc[self.date].dropna()\n",
    "                return weights[weights != 0]\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "    strategy = Backtest(price_asset=price_df, frequency=\"D\").simulate(\n",
    "        start=allocation_df.index[0]\n",
    "    )\n",
    "\n",
    "    return strategy\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\vip\\OneDrive\\DWS\\ABL_RESULT\\MLP_ALLOCATION.xlsx\"\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "allocation = pd.read_excel(path, \"allocation\", index_col=[1, 2, 0], parse_dates=True)\n",
    "allocation = allocation.unstack().unstack()[\"weights\"]\n",
    "\n",
    "stra = \"US_5\"\n",
    "\n",
    "allo = allocation[stra].dropna(how=\"all\", axis=1)\n",
    "\n",
    "tickers = \", \".join(allo.columns.tolist())\n",
    "tickers = tickers.replace(\".KS\", \"\")\n",
    "tickers = (\n",
    "    tickers\n",
    "    if isinstance(tickers, (list, set, tuple))\n",
    "    else tickers.replace(\",\", \" \").upper().split()\n",
    ")\n",
    "\n",
    "prices = []\n",
    "if stra.startswith(\"KR\"):\n",
    "    for ticker in tickers:\n",
    "        price = pdr.DataReader(ticker, \"naver\", start=\"1990-1-1\").astype(float)[\"Close\"]\n",
    "        price.name = ticker + \".KS\"\n",
    "        prices.append(price)\n",
    "\n",
    "    prices = pd.concat(prices, axis=1)\n",
    "\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "if stra.startswith(\"US\"):\n",
    "    import yfinance as yf\n",
    "\n",
    "    prices = yf.download(tickers)[\"Adj Close\"]\n",
    "\n",
    "result = backtest(allocation_df=allo, price_df=prices)\n",
    "\n",
    "with pd.ExcelWriter(f\"{stra}.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    # Save each dataframe to a separate sheet in the Excel file\n",
    "    value = result.value_df\n",
    "    value.index.name = \"date\"\n",
    "    weights = result.weights_df\n",
    "    weights.index.name = \"date\"\n",
    "    al = result.reb_weights_df.dropna(how=\"all\")\n",
    "    al.index.name = \"date\"\n",
    "\n",
    "    value.to_excel(writer, sheet_name=\"value\")\n",
    "    weights.to_excel(writer, sheet_name=\"weights\")\n",
    "    al.to_excel(writer, sheet_name=\"allocations\")\n",
    "\n",
    "value.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
