{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def to_pri_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_pri_return(price: pd.Series) -> float:\n",
    "        return price.dropna().pct_change().fillna(0)\n",
    "\n",
    "    return prices.apply(to_pri_return)\n",
    "\n",
    "\n",
    "def to_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    return to_pri_returns(prices=prices).apply(np.log1p)\n",
    "\n",
    "\n",
    "def to_num_years(prices: pd.DataFrame) -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_num_year(price) -> float:\n",
    "        p = price.dropna()\n",
    "        start = parser.parse(str(p.index[0]))\n",
    "        end = parser.parse(str(p.index[-1]))\n",
    "        return (end - start).days / 365.0\n",
    "\n",
    "    return prices.apply(to_num_year, axis=0)\n",
    "\n",
    "\n",
    "def to_num_bars(prices: pd.DataFrame) -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_num_bar(price) -> float:\n",
    "        return len(price.dropna())\n",
    "\n",
    "    return prices.apply(to_num_bar, axis=0)\n",
    "\n",
    "\n",
    "def to_ann_factors(prices: pd.DataFrame) -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return to_num_bars(prices=prices) / to_num_years(prices=prices)\n",
    "\n",
    "\n",
    "def to_cum_returns(prices: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return to_pri_returns(prices=prices).add(1).prod() - 1\n",
    "\n",
    "\n",
    "def to_ann_returns(prices: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return (\n",
    "        to_pri_returns(prices=prices).add(1).prod() ** (1 / to_num_years(prices=prices))\n",
    "        - 1\n",
    "    )\n",
    "\n",
    "\n",
    "def to_ann_variances(\n",
    "    prices: pd.DataFrame, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    if not ann_factors:\n",
    "        ann_factors = to_ann_factors(prices=prices)\n",
    "    return to_pri_returns(prices=prices).var() * to_ann_factors(prices=prices)\n",
    "\n",
    "\n",
    "def to_ann_volatilites(\n",
    "    prices: pd.DataFrame, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return to_ann_variances(prices=prices, ann_factors=ann_factors).apply(np.sqrt)\n",
    "\n",
    "\n",
    "def to_ann_semi_variances(\n",
    "    prices: pd.DataFrame, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    pri_returns = to_pri_returns(prices=prices)\n",
    "    positive_pri_returns = pri_returns[pri_returns >= 0]\n",
    "    if not ann_factors:\n",
    "        ann_factors = to_ann_factors(prices=prices)\n",
    "    return positive_pri_returns.var() * ann_factors\n",
    "\n",
    "\n",
    "def to_ann_semi_volatilities(\n",
    "    prices: pd.DataFrame, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        ann_factors (Optional[float], optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return to_ann_semi_variances(prices=prices, ann_factors=ann_factors) ** 0.5\n",
    "\n",
    "\n",
    "def to_drawdown(\n",
    "    prices: pd.DataFrame,\n",
    "    window: Optional[int] = None,\n",
    "    min_periods: Optional[int] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        window (Optional[int], optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    if window:\n",
    "        return prices / prices.rolling(window=window, min_periods=min_periods).max() - 1\n",
    "    return prices / prices.expanding(min_periods=min_periods or 1).max() - 1\n",
    "\n",
    "\n",
    "def to_max_drawdown(\n",
    "    prices: pd.DataFrame,\n",
    "    window: Optional[int] = None,\n",
    "    min_periods: Optional[int] = None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        window (Optional[int], optional): _description_. Defaults to None.\n",
    "        min_periods (Optional[int], optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    return to_drawdown(prices=prices, window=window, min_periods=min_periods).min()\n",
    "\n",
    "\n",
    "def to_sharpe_ratios(\n",
    "    prices: pd.DataFrame, risk_free: float = 0.0, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        risk_free (float, optional): _description_. Defaults to 0..\n",
    "        ann_factors (Optional[float], optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    excess_returns = to_ann_returns(prices=prices) - risk_free\n",
    "    return excess_returns / to_ann_volatilites(prices=prices, ann_factors=ann_factors)\n",
    "\n",
    "\n",
    "def to_sortino_ratios(\n",
    "    prices: pd.DataFrame, ann_factors: Optional[float] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        ann_factors (Optional[float], optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    if not ann_factors:\n",
    "        ann_factors = to_ann_factors(prices=prices)\n",
    "\n",
    "    ann_returns = to_ann_returns(prices=prices)\n",
    "    ann_semi_volatilities = to_ann_semi_volatilities(\n",
    "        prices=prices, ann_factors=ann_factors\n",
    "    )\n",
    "\n",
    "    return ann_returns / ann_semi_volatilities\n",
    "\n",
    "\n",
    "def to_tail_ratios(prices: pd.DataFrame, alpha: float = 0.05) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        alpha (float, optional): _description_. Defaults to 0.05.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_tail_ratio(pri_return: pd.Series, alpha: float) -> float:\n",
    "\n",
    "        r = pri_return.dropna()\n",
    "        return -r.quantile(q=alpha) / r.quantile(q=1 - alpha)\n",
    "\n",
    "    return to_pri_returns(prices=prices).apply(to_tail_ratio, alpha=alpha)\n",
    "\n",
    "\n",
    "def to_skewnesses(prices: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_skewness(pri_return: pd.Series) -> float:\n",
    "\n",
    "        return pri_return.dropna().skew()\n",
    "\n",
    "    return to_pri_returns(prices=prices).apply(to_skewness)\n",
    "\n",
    "\n",
    "def to_kurtosises(prices: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def to_kurtosis(pri_return: pd.Series) -> float:\n",
    "\n",
    "        return pri_return.dropna().kurt()\n",
    "\n",
    "    return to_pri_returns(prices=prices).apply(to_kurtosis)\n",
    "\n",
    "\n",
    "def to_value_at_risks(prices: pd.DataFrame, alpha: float = 0.05) -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        prices (pd.DataFrame): _description_\n",
    "        alpha (float, optional): _description_. Defaults to 0.05.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: _description_\n",
    "    \"\"\"\n",
    "    def to_value_at_risk(pri_return: pd.Series, alpha: float) -> float:\n",
    "\n",
    "        r = pri_return.dropna()\n",
    "        return r.quantile(q=alpha)\n",
    "\n",
    "    return to_pri_returns(prices=prices).apply(to_value_at_risk, alpha=alpha)\n",
    "\n",
    "def to_expected_shortfalls(prices: pd.DataFrame, alpha: float = 0.05) -> pd.Series:\n",
    "    \n",
    "    def to_expected_shortfall(pri_return: pd.Series, alpha: float) -> float:\n",
    "\n",
    "        r = pri_return.dropna()\n",
    "        var = r.quantile(q=alpha)\n",
    "        return r[r <= var].mean()\n",
    "\n",
    "    return to_pri_returns(prices=prices).apply(to_expected_shortfall, alpha=alpha)    \n",
    "\n",
    "\n",
    "\n",
    "def cov_to_corr(covariance_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        covariance_matrix (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    vol = np.sqrt(np.diag(covariance_matrix))\n",
    "    corr = covariance_matrix / np.outer(vol, vol)\n",
    "    corr[corr < -1], corr[corr > 1] = -1, 1\n",
    "    return corr\n",
    "\n",
    "\n",
    "def recursive_bisection(sorted_tree) -> List[Tuple[List[int], List[int]]]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sorted_tree (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[List[int], List[int]]]: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    if len(sorted_tree) < 3:\n",
    "        return\n",
    "\n",
    "    num = len(sorted_tree)\n",
    "    bis = int(num / 2)\n",
    "    left = sorted_tree[0:bis]\n",
    "    right = sorted_tree[bis:]\n",
    "    if len(left) > 2 and len(right) > 2:\n",
    "        return [(left, right), recursive_bisection(left), recursive_bisection(right)]\n",
    "    return (left, right)\n",
    "\n",
    "\n",
    "def get_cluster_assets(clusters, node, num_assets) -> List:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        clusters (_type_): _description_\n",
    "        node (_type_): _description_\n",
    "        num_assets (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        List: _description_\n",
    "    \"\"\"\n",
    "    if node < num_assets:\n",
    "        return [int(node)]\n",
    "    row = clusters[int(node - num_assets)]\n",
    "    return get_cluster_assets(clusters, row[0], num_assets) + get_cluster_assets(\n",
    "        clusters, row[1], num_assets\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IVV    -0.029683\n",
       "IWV    -0.030038\n",
       "MTUM   -0.030403\n",
       "QQQ    -0.041682\n",
       "QUAL   -0.027506\n",
       "SPY    -0.028441\n",
       "VLUE   -0.029014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "prices = yf.download(\"SPY, QQQ, IWV, MTUM, QUAL, VLUE, IVV\")[\"Adj Close\"]\n",
    "to_expected_shortfalls(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IVV    -0.019268\n",
       "IWV    -0.019255\n",
       "MTUM   -0.018910\n",
       "QQQ    -0.028050\n",
       "QUAL   -0.016566\n",
       "SPY    -0.018511\n",
       "VLUE   -0.018602\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_value_at_risks(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IVV    -1.077696\n",
       "IWV    -1.054462\n",
       "MTUM   -1.074796\n",
       "QQQ    -1.077147\n",
       "QUAL   -1.030019\n",
       "SPY    -1.087807\n",
       "VLUE   -1.069519\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IVV     0.146015\n",
       "IWV     0.144096\n",
       "MTUM    0.141989\n",
       "QQQ     0.127689\n",
       "QUAL    0.146680\n",
       "SPY     0.147329\n",
       "VLUE    0.146203\n",
       "Name: weights, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.risk_parity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IVV</th>\n",
       "      <th>IWV</th>\n",
       "      <th>MTUM</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>VLUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IVV</th>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.031482</td>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.031620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IWV</th>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.032430</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.032318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTUM</th>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.032430</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>0.038143</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>0.029708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.038143</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0.035207</td>\n",
       "      <td>0.032576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUAL</th>\n",
       "      <td>0.031482</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.031266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>0.035207</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.031061</td>\n",
       "      <td>0.031233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLUE</th>\n",
       "      <td>0.031620</td>\n",
       "      <td>0.032318</td>\n",
       "      <td>0.029708</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>0.031266</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.037283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           IVV       IWV      MTUM       QQQ      QUAL       SPY      VLUE\n",
       "IVV   0.031828  0.032260  0.031828  0.035591  0.031482  0.031414  0.031620\n",
       "IWV   0.032260  0.032964  0.032430  0.036123  0.031936  0.031855  0.032318\n",
       "MTUM  0.031828  0.032430  0.038901  0.038143  0.031308  0.031420  0.029708\n",
       "QQQ   0.035591  0.036123  0.038143  0.046259  0.035353  0.035207  0.032576\n",
       "QUAL  0.031482  0.031936  0.031308  0.035353  0.032207  0.031123  0.031266\n",
       "SPY   0.031414  0.031855  0.031420  0.035207  0.031123  0.031061  0.031233\n",
       "VLUE  0.031620  0.032318  0.029708  0.032576  0.031266  0.031233  0.037283"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = optimizer.covariance_matrix\n",
    "cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03182801 0.03239127 0.03518713 0.03837091 0.0320171  0.03144203\n",
      "  0.03444766]\n",
      " [0.03239127 0.03296449 0.03580984 0.03904996 0.03258371 0.03199845\n",
      "  0.03505727]\n",
      " [0.03518713 0.03580984 0.03890077 0.04242057 0.03539618 0.03476041\n",
      "  0.03808325]\n",
      " [0.03837091 0.03904996 0.04242057 0.04625884 0.03859887 0.03790558\n",
      "  0.04152908]\n",
      " [0.0320171  0.03258371 0.03539618 0.03859887 0.03220732 0.03162882\n",
      "  0.03465231]\n",
      " [0.03144203 0.03199845 0.03476041 0.03790558 0.03162882 0.03106072\n",
      "  0.0340299 ]\n",
      " [0.03444766 0.03505727 0.03808325 0.04152908 0.03465231 0.0340299\n",
      "  0.03728291]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IVV</th>\n",
       "      <th>IWV</th>\n",
       "      <th>MTUM</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>VLUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IVV</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995939</td>\n",
       "      <td>0.904524</td>\n",
       "      <td>0.927553</td>\n",
       "      <td>0.983290</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.917913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IWV</th>\n",
       "      <td>0.995939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905626</td>\n",
       "      <td>0.925056</td>\n",
       "      <td>0.980130</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.921854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTUM</th>\n",
       "      <td>0.904524</td>\n",
       "      <td>0.905626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899166</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.903899</td>\n",
       "      <td>0.780070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>0.927553</td>\n",
       "      <td>0.925056</td>\n",
       "      <td>0.899166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915910</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.784404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUAL</th>\n",
       "      <td>0.983290</td>\n",
       "      <td>0.980130</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.915910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984018</td>\n",
       "      <td>0.902273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.903899</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.984018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLUE</th>\n",
       "      <td>0.917913</td>\n",
       "      <td>0.921854</td>\n",
       "      <td>0.780070</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.902273</td>\n",
       "      <td>0.917825</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           IVV       IWV      MTUM       QQQ      QUAL       SPY      VLUE\n",
       "IVV   1.000000  0.995939  0.904524  0.927553  0.983290  0.999117  0.917913\n",
       "IWV   0.995939  1.000000  0.905626  0.925056  0.980130  0.995516  0.921854\n",
       "MTUM  0.904524  0.905626  1.000000  0.899166  0.884501  0.903899  0.780070\n",
       "QQQ   0.927553  0.925056  0.899166  1.000000  0.915910  0.928798  0.784404\n",
       "QUAL  0.983290  0.980130  0.884501  0.915910  1.000000  0.984018  0.902273\n",
       "SPY   0.999117  0.995516  0.903899  0.928798  0.984018  1.000000  0.917825\n",
       "VLUE  0.917913  0.921854  0.780070  0.784404  0.902273  0.917825  1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "source": [
    "def quasi_diagnalization(clusters, num_assets, curr_index):\n",
    "    \"\"\"Rearrange the assets to reorder them according to hierarchical tree clustering order\"\"\"\n",
    "\n",
    "    if curr_index < num_assets:\n",
    "        return [curr_index]\n",
    "\n",
    "    left = int(clusters[curr_index - num_assets, 0])\n",
    "    right = int(clusters[curr_index - num_assets, 1])\n",
    "\n",
    "    return quasi_diagnalization(clusters, num_assets, left) + quasi_diagnalization(\n",
    "        clusters, num_assets, right\n",
    "    )\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import to_tree, linkage, dendrogram\n",
    "import yfinance as yf\n",
    "\n",
    "prices = yf.download(\"SPY, QQQ, IWV, MTUM, QUAL, VLUE, IVV\")[\"Adj Close\"].dropna()\n",
    "expected_returns = prices.pct_change().fillna(0).mean() * 252\n",
    "covariance_matrix = prices.pct_change().fillna(0).cov() * (252)\n",
    "corr = cov_to_corr(covariance_matrix.values)\n",
    "dist = np.sqrt((1 - corr).round(5) / 2)\n",
    "clusters = linkage(squareform(dist), method=\"single\")\n",
    "sorted_index = list(to_tree(clusters, rd=False).pre_order())\n",
    "# clustered_assets = [[self.assets[x] for x in sorted_index]]\n",
    "# print(sorted_index)\n",
    "# dendrogram(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([2, 6, 3], [4, 1, 0, 5]), [([2], [6, 3])], [([4, 1], [0, 5])]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "print(recursive_bisection(sorted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index\n",
    "\n",
    "\n",
    "def divide_chunks(l, n):\n",
    "\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i : i + n]\n",
    "\n",
    "\n",
    "for i in range(len(sorted_index) - 2, 0, -1):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    print(list(divide_chunks(sorted_index, i)))\n",
    "    # print(list(divide_chunks(sorted_index, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_variance_weights(covariance_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"calculate weights of inverse variance. (tot weights = 100%)\n",
    "\n",
    "    Args:\n",
    "        covariance_matrix (np.ndarray): _description_\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: weights of\n",
    "    \"\"\"\n",
    "    inv_var_weights = 1 / np.diag(covariance_matrix)\n",
    "    inv_var_weights /= inv_var_weights.sum()\n",
    "    return inv_var_weights\n",
    "\n",
    "\n",
    "inverse_variance_weights(covariance_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_excel(\"database.xlsx\", sheet_name=\"tb_meta\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# for id, m in meta.iterrows():\n",
    "#     tic = yf.Ticker(m.ticker)\n",
    "#     ff = tic.isin\n",
    "#     print(ff)\n",
    "\n",
    "for id, row in meta.iterrows():\n",
    "    print(row.ticker)\n",
    "    if row.__ticker.endswith(\".KS\"):\n",
    "        continue\n",
    "\n",
    "    t = yf.Ticker(row.ticker)\n",
    "\n",
    "    hist = t.history(period=\"1y\")\n",
    "    try:\n",
    "        splits = hist[\"Stock Splits\"]\n",
    "\n",
    "        test = (splits != 0).any()\n",
    "        if test:\n",
    "            print(\"Has splits\")\n",
    "            print(row.ticker)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "t = yf.Ticker(\"HYMB\")\n",
    "hist = t.history(period=\"1y\")\n",
    "splits = hist[\"Stock Splits\"]\n",
    "splits = splits[splits != 0]\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" base strategy class \"\"\"\n",
    "\n",
    "import warnings\n",
    "from typing import Any, List, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Account:\n",
    "    \"\"\"strategy account\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.date: List = []\n",
    "        self.value: List = []\n",
    "        self.weights: List[Dict] = []\n",
    "        self.reb_weights: List[Dict] = []\n",
    "        self.trade_weights: List[Dict] = []\n",
    "\n",
    "\n",
    "class BaseStrategy:\n",
    "    \"\"\"\n",
    "    BaseStrategy class is an algorithmic trading strategy that sequentially allocates capital among\n",
    "    group of assets based on pre-defined allocatioin method.\n",
    "\n",
    "    BaseStrategy shall be the parent class for all investment strategies with period-wise\n",
    "    rebalancing scheme.\n",
    "\n",
    "    Using this class requires following pre-defined methods:\n",
    "    1. rebalance(self, price_asset, date, **kwargs):\n",
    "        the method shall be in charge of calculating new weights based on prices\n",
    "        that are avaiable.\n",
    "    2. monitor (self, ...):\n",
    "        the method shall be in charge of monitoring the strategy status, and if\n",
    "        necessary call the rebalance method to re-calculate weights. aka irregular rebalancing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        price_asset: pd.DataFrame,\n",
    "        frequency: str = \"M\",\n",
    "        min_assets: int = 2,\n",
    "        min_periods: int = 2,\n",
    "        investment: float = 1000.0,\n",
    "        commission: int = 0,\n",
    "        currency: str = \"KRW\",\n",
    "        name: str = \"strategy\",\n",
    "        account: Optional[Account] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.price_asset: pd.DataFrame = self.check_price_df(price_asset)\n",
    "        self.frequency: str = frequency\n",
    "        self.min_assets: int = min_assets\n",
    "        self.min_periods: int = min_periods\n",
    "        self.name: str = name\n",
    "        self.commission = commission\n",
    "        self.currency = currency\n",
    "\n",
    "        # account information\n",
    "        self.idx: int = 0\n",
    "        self.date: Any = None\n",
    "        self.value: float = investment\n",
    "        self.weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.reb_weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.trade_weights: pd.Series = pd.Series(dtype=float)\n",
    "        self.account: Account = account or Account()\n",
    "\n",
    "    ################################################################################################\n",
    "    @property\n",
    "    def value_df(self):\n",
    "        \"\"\"values dataframe\"\"\"\n",
    "        return pd.DataFrame(\n",
    "            data=self.account.value, index=self.account.date, columns=[\"value\"]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.weights, index=self.account.date)\n",
    "\n",
    "    @property\n",
    "    def reb_weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.reb_weights, index=self.account.date)\n",
    "\n",
    "    @property\n",
    "    def trade_weights_df(self):\n",
    "        \"\"\"weights dataframe\"\"\"\n",
    "        return pd.DataFrame(data=self.account.trade_weights, index=self.account.date)\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    def update_book(self) -> None:\n",
    "        \"\"\"update the account value based on the current date\"\"\"\n",
    "        prices = self.price_asset.loc[self.date]\n",
    "        if not self.weights.empty:\n",
    "            print(f\"update book values\")\n",
    "            pre_prices = self.price_asset.iloc[\n",
    "                self.price_asset.index.get_loc(self.date) - 1\n",
    "            ]\n",
    "            capitals = self.weights * self.value\n",
    "            pri_return = prices / pre_prices\n",
    "            new_capitals = capitals * pri_return.loc[capitals.index]\n",
    "            profit_loss = new_capitals - capitals\n",
    "            self.value += profit_loss.sum()\n",
    "            self.weights = new_capitals / self.value\n",
    "\n",
    "        if not self.reb_weights.empty:\n",
    "            print(f\"make re-allocation {self.reb_weights.to_dict()}\")\n",
    "            # reindex to contain the same asset.\n",
    "            union_assets = self.reb_weights.index.union(self.weights.index)\n",
    "            self.weights = self.weights.reindex(union_assets, fill_value=0)\n",
    "            self.reb_weights = self.reb_weights.reindex(union_assets, fill_value=0)\n",
    "            self.trade_weights = self.reb_weights.subtract(self.weights)\n",
    "            trade_capitals = self.value * self.trade_weights\n",
    "            trade_costs = trade_capitals.abs() * self.commission / 10_000\n",
    "            trade_cost = trade_costs.sum()\n",
    "            # update the account metrics.\n",
    "            self.value -= trade_cost\n",
    "            self.weights = self.reb_weights\n",
    "\n",
    "        # do nothing if no account data.\n",
    "        if self.weights.empty and self.reb_weights.empty:\n",
    "            return\n",
    "        # loop through all variables in account history\n",
    "        for name in vars(self.account).keys():\n",
    "            getattr(self.account, name).append(getattr(self, name))\n",
    "        # clear the rebalancing weights.\n",
    "        self.reb_weights = pd.Series(dtype=float)\n",
    "        self.trade_weights = pd.Series(dtype=float)\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    def simulate(self, start: ... = None, end: ... = None) -> ...:\n",
    "        \"\"\"simulate historical strategy perfromance\"\"\"\n",
    "        start = start or self.price_asset.index[0]\n",
    "        end = end or self.price_asset.index[-1]\n",
    "        reb_dates = pd.date_range(start=start, end=end, freq=self.frequency)\n",
    "        for self.date in pd.date_range(start=start, end=end, freq=\"D\"):\n",
    "            print(self.date)\n",
    "            if self.date in self.price_asset.index:\n",
    "                self.update_book()\n",
    "            if self.weights.empty or self.monitor() or self.date in reb_dates:\n",
    "                if not self.reb_weights.empty:\n",
    "                    continue\n",
    "                self.reb_weights = self.allocate(self.date)\n",
    "                print(f\"rebalancing weights: {self.reb_weights.to_dict()}\")\n",
    "        return self\n",
    "\n",
    "    def allocate(self, date: ... = None) -> pd.Series:\n",
    "        \"\"\"allocate weights based on date if date not provided use latest\"\"\"\n",
    "        # pylint: disable=multiple-statements\n",
    "        date = date or self.price_asset.index[-1]\n",
    "        price_slice = self.price_asset.loc[:date].dropna(\n",
    "            thresh=self.min_periods, axis=1\n",
    "        )\n",
    "        if price_slice.empty:\n",
    "            return pd.Series(dtype=float)\n",
    "        reb_weights = self.rebalance(price_asset=price_slice)\n",
    "        if reb_weights is None:\n",
    "            return pd.Series(dtype=float)\n",
    "        return self.clean_weights(reb_weights, decimals=4)\n",
    "\n",
    "    def rebalance(self, price_asset: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Default rebalancing method\"\"\"\n",
    "        asset = price_asset.columns\n",
    "        uniform_weight = np.ones(len(asset))\n",
    "        uniform_weight /= uniform_weight.sum()\n",
    "        weight = pd.Series(index=asset, data=uniform_weight)\n",
    "        return weight\n",
    "\n",
    "    def monitor(self) -> bool:\n",
    "        \"\"\"Default monitoring method.\"\"\"\n",
    "        return False\n",
    "\n",
    "    ################################################################################################\n",
    "    @staticmethod\n",
    "    def check_price_df(price_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Check the price_df.\n",
    "\n",
    "        Args:\n",
    "            price_df (pd.DataFrame): _description_\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if price_df is not pd.DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: price_df\n",
    "        \"\"\"\n",
    "        if not isinstance(price_df, pd.DataFrame):\n",
    "            raise TypeError(\"price_df must be a pd.DataFrame.\")\n",
    "        if not isinstance(price_df.index, pd.DatetimeIndex):\n",
    "            warnings.warn(\"converting price_df's index to pd.DatetimeIndex.\")\n",
    "            price_df.index = pd.to_datetime(price_df.index)\n",
    "        return price_df\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_weights(weights: pd.Series, decimals: int = 4) -> pd.Series:\n",
    "        \"\"\"Clean weights based on the number decimals and maintain the total of weights.\n",
    "\n",
    "        Args:\n",
    "            weights (pd.Series): asset weights.\n",
    "            decimals (int, optional): number of decimals to be rounded for\n",
    "                weight. Defaults to 4.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: clean asset weights.\n",
    "        \"\"\"\n",
    "        # clip weight values by minimum and maximum.\n",
    "        tot_weight = weights.sum().round(4)\n",
    "        weights = weights.round(decimals=decimals)\n",
    "        # repeat round and weight calculation.\n",
    "        for _ in range(10):\n",
    "            weights = weights / weights.sum() * tot_weight\n",
    "            weights = weights.round(decimals=decimals)\n",
    "            if weights.sum() == tot_weight:\n",
    "                return weights\n",
    "        # if residual remains after repeated rounding.\n",
    "        # allocate the the residual weight on the max weight.\n",
    "        residual = tot_weight - weights.sum()\n",
    "        # !!! Error may occur when there are two max weights???\n",
    "        weights[np.argmax(weights)] += np.round(residual, decimals=decimals)\n",
    "        return weights\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "def backtest(allocation_df: pd.DataFrame, price_df: pd.DataFrame) -> BaseStrategy:\n",
    "    \"\"\"provide a backtested strategy.\n",
    "\n",
    "    Args:\n",
    "        allocation_df (pd.DataFrame): allocation dataframe.\n",
    "        price_df (pd.DataFrame): asset price dataframe.\n",
    "\n",
    "    Returns:\n",
    "        BaseStrategy: backtested strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    class Backtest(BaseStrategy):\n",
    "        \"\"\"backtest class\"\"\"\n",
    "\n",
    "        def rebalance(self, price_asset: pd.DataFrame) -> pd.Series:\n",
    "            if self.date in allocation_df.index:\n",
    "                weights = allocation_df.loc[self.date].dropna()\n",
    "                return weights[weights != 0]\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "    strategy = Backtest(price_asset=price_df, frequency=\"D\").simulate(\n",
    "        start=allocation_df.index[0]\n",
    "    )\n",
    "\n",
    "    return strategy\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\vip\\OneDrive\\DWS\\ABL_RESULT\\MLP_ALLOCATION.xlsx\"\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "allocation = pd.read_excel(path, \"allocation\", index_col=[1, 2, 0], parse_dates=True)\n",
    "allocation = allocation.unstack().unstack()[\"weights\"]\n",
    "\n",
    "stra = \"US_5\"\n",
    "\n",
    "allo = allocation[stra].dropna(how=\"all\", axis=1)\n",
    "\n",
    "tickers = \", \".join(allo.columns.tolist())\n",
    "tickers = tickers.replace(\".KS\", \"\")\n",
    "tickers = (\n",
    "    tickers\n",
    "    if isinstance(tickers, (list, set, tuple))\n",
    "    else tickers.replace(\",\", \" \").upper().split()\n",
    ")\n",
    "\n",
    "prices = []\n",
    "if stra.startswith(\"KR\"):\n",
    "    for ticker in tickers:\n",
    "        price = pdr.DataReader(ticker, \"naver\", start=\"1990-1-1\").astype(float)[\"Close\"]\n",
    "        price.name = ticker + \".KS\"\n",
    "        prices.append(price)\n",
    "\n",
    "    prices = pd.concat(prices, axis=1)\n",
    "\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "if stra.startswith(\"US\"):\n",
    "    import yfinance as yf\n",
    "\n",
    "    prices = yf.download(tickers)[\"Adj Close\"]\n",
    "\n",
    "result = backtest(allocation_df=allo, price_df=prices)\n",
    "\n",
    "with pd.ExcelWriter(f\"{stra}.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    # Save each dataframe to a separate sheet in the Excel file\n",
    "    value = result.value_df\n",
    "    value.index.name = \"date\"\n",
    "    weights = result.weights_df\n",
    "    weights.index.name = \"date\"\n",
    "    al = result.reb_weights_df.dropna(how=\"all\")\n",
    "    al.index.name = \"date\"\n",
    "\n",
    "    value.to_excel(writer, sheet_name=\"value\")\n",
    "    weights.to_excel(writer, sheet_name=\"weights\")\n",
    "    al.to_excel(writer, sheet_name=\"allocations\")\n",
    "\n",
    "value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
