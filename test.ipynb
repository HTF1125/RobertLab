{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1927-12-30      17.660000\n",
       "1928-01-03      17.760000\n",
       "1928-01-04      17.719999\n",
       "1928-01-05      17.549999\n",
       "1928-01-06      17.660000\n",
       "                 ...     \n",
       "2023-06-20    4388.709961\n",
       "2023-06-21    4365.689941\n",
       "2023-06-22    4381.890137\n",
       "2023-06-23    4348.330078\n",
       "2023-06-26    4328.819824\n",
       "Name: Adj Close, Length: 23985, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.backend import data\n",
    "import yfinance as yf\n",
    "\n",
    "price = yf.download(tickers=\"^GSPC\", progress=False)[\"Adj Close\"]\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.PLATFORM  = \"Streamlit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Streamlit'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.PLATFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def factor_information_coefficient(\n",
    "    factor_data, group_adjust=False, by_group=False, method=stats.spearmanr\n",
    "):\n",
    "    def src_ic(group):\n",
    "        f = group[\"factor\"]\n",
    "        _ic = group[[\"period_1\", \"period_252\"]].apply(lambda x: method(x, f)[0])\n",
    "        return _ic\n",
    "\n",
    "    factor_data = factor_data.copy()\n",
    "\n",
    "    grouper = [factor_data.index.get_level_values(\"date\")]\n",
    "\n",
    "    # if group_adjust:\n",
    "    #     factor_data = demean_forward_returns(factor_data, grouper + ['group'])\n",
    "    # if by_group:\n",
    "    #     grouper.append('group')\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        ic = factor_data.groupby(grouper).apply(src_ic)\n",
    "\n",
    "    return ic\n",
    "\n",
    "\n",
    "ic = factor_information_coefficient(far.clean_factor_data)\n",
    "\n",
    "ic.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far = ja.FactorAnalyzer(\n",
    "    prices=prices,\n",
    "    factor=factorsdata,  # factor_data 为因子值的 pandas.DataFrame\n",
    "    quantiles=10,\n",
    "    periods=(1, 252),\n",
    "    max_loss=0.9,\n",
    ")\n",
    "\n",
    "far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far._clean_factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import signals, data\n",
    "import pandas as pd\n",
    "\n",
    "df = data.get_oecd_us_leading_indicator()\n",
    "df.index = df.index + pd.DateOffset(months=1)\n",
    "df = df.resample(\"M\").last().dropna()\n",
    "\n",
    "df = df.diff()\n",
    "mean = df.rolling(12 * 5).mean()\n",
    "std = df.rolling(12 * 5).std()\n",
    "normalized = (df - mean) / std\n",
    "\n",
    "normalized = normalized.clip(-3, 3).dropna()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Create the bar plot\n",
    "fig = go.Figure(data=go.Bar(x=normalized.index, y=normalized[\"USALOLITONOSTSAM\"]))\n",
    "\n",
    "# Customize the plot layout\n",
    "fig.update_layout(title=\"Bar Plot\", xaxis_title=\"Categories\", yaxis_title=\"Values\")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend.loc[\"2015\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import data, metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "total_iter = 12 * 20 * 10\n",
    "prices = data.get_prices(\"SPY, AGG, TLT\").resample(\"M\").last()\n",
    "\n",
    "log_return = metrics.to_log_return(prices=prices)\n",
    "expected_return = log_return.mean()\n",
    "expected_riks = log_return.std()\n",
    "cov = log_return.cov()\n",
    "corr_cov = np.linalg.cholesky(cov)\n",
    "z = np.random.normal(0, 1, size=(len(prices.columns), total_iter))\n",
    "\n",
    "drift = np.full((total_iter, len(prices.columns)), expected_return).T\n",
    "shock = np.dot(corr_cov, z)\n",
    "\n",
    "monthly_returns = drift + shock\n",
    "pd.DataFrame(\n",
    "    np.transpose(monthly_returns),\n",
    "    columns=prices.columns,\n",
    "    # index=pd.date_range(start=\"2023-6-8\", periods=total_iter, freq=\"M\"),\n",
    ").cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def to_macd(\n",
    "    prices: pd.DataFrame,\n",
    "    fast_window: int = 12,\n",
    "    slow_window: int = 26,\n",
    "    signal_window: int = 9,\n",
    ") -> pd.DataFrame:\n",
    "    MACD = (\n",
    "        +prices.ewm(span=fast_window, min_periods=fast_window).mean()\n",
    "        - prices.ewm(span=slow_window, min_periods=slow_window).mean()\n",
    "    )\n",
    "    signal = MACD.ewm(span=signal_window, min_periods=slow_window).mean()\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "to_macd(prices).loc[\"2022\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    prices.ewm(span=12, min_periods=12).mean()\n",
    "    - prices.ewm(span=26, min_periods=26).mean()\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_curve = {\"T10Y2Y\": \"10Y-2Y\", \"T10Y3M\": \"10Y-3M\"}\n",
    "\n",
    "yield_curve_data = data.get_macro(list(yield_curve.keys())).loc[\"2019\":]\n",
    "yield_curve_data = yield_curve_data.rename(columns=yield_curve)\n",
    "yield_curve_data.head().to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "px.line(yield_curve_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Get the index of a value in the list\n",
    "value = 30\n",
    "\n",
    "if value in my_list:\n",
    "    index = my_list.index(value)\n",
    "    print(\"Index of\", value, \"in the list:\", index)\n",
    "else:\n",
    "    print(value, \"is not present in the list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core.factors import price_momentum_diffusion\n",
    "from pkg.src.core import data\n",
    "\n",
    "price_momentum_diffusion(tickers=\"SPY, ACWI, XLY, XLP, AGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "prices = data.get_prices(tickers=\"SPY, ACWI, XLY, XLP, AGG\")\n",
    "momentums = (\n",
    "    pd.concat(\n",
    "        objs=[\n",
    "            metrics.rolling.to_momentum(prices=prices, months=1).stack(),\n",
    "            metrics.rolling.to_momentum(prices=prices, months=2).stack(),\n",
    "            metrics.rolling.to_momentum(prices=prices, months=3).stack(),\n",
    "            metrics.rolling.to_momentum(prices=prices, months=6).stack(),\n",
    "            metrics.rolling.to_momentum(prices=prices, months=9).stack(),\n",
    "            metrics.rolling.to_momentum(prices=prices, months=12).stack(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .apply(np.sign)\n",
    "    .sum(axis=1)\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import factors\n",
    "\n",
    "factors.volatility_3m(tickers=\"SPY, AGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import data\n",
    "\n",
    "data.get_universe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core.metrics.rolling import to_momentum\n",
    "from pkg.src.core import data\n",
    "from pkg.src.core.strategies import BacktestManager\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def to_standard_scalar(features: pd.Series) -> pd.Series:\n",
    "    scalar = (features - features.mean()) / features.std()\n",
    "    return scalar\n",
    "\n",
    "\n",
    "def to_standard_percentile(features: pd.Series) -> pd.Series:\n",
    "    return to_standard_scalar(features=features).aggregate(norm.cdf)\n",
    "\n",
    "\n",
    "prices = data.get_prices(\"XLC, XLY, XLP, XLE, XLF, XLV, XLI, XLB, XLRE, XLK, XLU\")\n",
    "\n",
    "bt = BacktestManager(prices=prices)\n",
    "features = to_momentum(prices=prices, months=12).apply(to_standard_percentile, axis=1)\n",
    "\n",
    "bt.Base(name=\"Strategy1\", start=\"2013-1-1\", features=features, percentile=0.8)\n",
    "#\n",
    "bt.strategies[\"Strategy1\"].allocations\n",
    "# features\n",
    "bt.strategies[\"Strategy1\"].value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import feature\n",
    "\n",
    "functions = [func for func in dir(feature) if callable(getattr(feature, func))]\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_momentum = data.price_momentum_1m(tickers=\"SPY, AGG\")\n",
    "pri_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# from core.signals import OECDUSLEIHP\n",
    "from pkg.core.strategies import BacktestManager\n",
    "\n",
    "# signal = OECDUSLEIHP.from_fred_data()\n",
    "\n",
    "\n",
    "def get_universe(name: str = \"USSECTOR\"):\n",
    "    with open(\"universe.json\") as f:\n",
    "        return json.load(f).get(name)\n",
    "\n",
    "\n",
    "from pkg.src.core import data\n",
    "\n",
    "prices = data.get_prices(tickers=list(get_universe().keys()))\n",
    "bt = BacktestManager(prices=prices, start=\"2007-1-1\", commission=10, shares_frac=0)\n",
    "# bt.Momentum(target_percentile=0.7, months=3)\n",
    "# bt.values.plot(figsize=(12, 10))\n",
    "# bt.analytics\n",
    "\n",
    "from core import metrics\n",
    "\n",
    "metrics.to_momentum(prices=prices.iloc[:, 0], months=12, skip_months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core import data\n",
    "\n",
    "\n",
    "data.get_universe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer.from_prices(prices=prices.loc[\"2017\"].dropna(axis=1))\n",
    "\n",
    "w = opt.hierarchical_risk_parity()\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.src.core.portfolios import objectives\n",
    "\n",
    "np.sum(\n",
    "    objectives.risk_contributions(\n",
    "        weights=w,\n",
    "        covariance_matrix=np.array(opt.covariance_matrix),\n",
    "        sub_covariance_matrix_idx=[8],\n",
    "    )\n",
    ")\n",
    "\n",
    "np.sum(\n",
    "    objectives.risk_contributions(\n",
    "        weights=w,\n",
    "        covariance_matrix=np.array(opt.covariance_matrix),\n",
    "        sub_covariance_matrix_idx=[0, 3],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives.expected_volatility(w, opt.covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.sqrt((1 - opt.correlation_matrix).round(5) / 2)\n",
    "clusters = linkage(squareform(dist), method=\"single\")\n",
    "sorted_tree = list(to_tree(clusters, rd=False).pre_order())\n",
    "\n",
    "print(sorted_tree)\n",
    "\n",
    "\n",
    "def recursive_bisection(sorted_tree):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sorted_tree (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[List[int], List[int]]]: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    left = sorted_tree[0 : int(len(sorted_tree) / 2)]\n",
    "    right = sorted_tree[int(len(sorted_tree) / 2) :]\n",
    "\n",
    "    if len(sorted_tree) < 3:\n",
    "        return (left, right)\n",
    "\n",
    "    cache = [(left, right)]\n",
    "    if len(left) > 2:\n",
    "        cache.extend(recursive_bisection(left))\n",
    "    if len(right) > 2:\n",
    "        cache.extend(recursive_bisection(right))\n",
    "    return cache\n",
    "\n",
    "\n",
    "cluster_sets = recursive_bisection(sorted_tree)\n",
    "\n",
    "for i in cluster_sets:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import data\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "tickers = {\n",
    "    \"T5YIE\": \"Breakeven Inflation: 5Y\",\n",
    "    \"T10YIE\": \"Breakeven Inflation: 10Y\",\n",
    "    \"T5YIFR\": \"Expectation Infaltiona: 5Y\",\n",
    "}\n",
    "\n",
    "result = data.get_macro(tickers=tickers).dropna()\n",
    "result[\"chg\"] = result[\"Breakeven Inflation: 10Y\"] - result[\"Breakeven Inflation: 5Y\"]\n",
    "spy = data.get_prices(tickers=\"SPY\")\n",
    "\n",
    "# Create a line plot for each series\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=spy.index, y=spy[\"SPY\"], mode=\"lines\", name=\"SPY\"), row=1, col=1\n",
    ")\n",
    "for series in result:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=result.index, y=result[series], mode=\"lines\", name=series),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Set the title and axis labels\n",
    "fig.update_layout(title=\"Inflation\", xaxis_title=\"Date\", yaxis_title=\"%\", height=600)\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list(\n",
    "                [\n",
    "                    dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\"),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "        rangeslider=dict(visible=False),\n",
    "        type=\"date\",\n",
    "    ),\n",
    "    hovermode=\"x unified\",  # Enable the \"Show All Stats\" option on mouseover\n",
    ")\n",
    "\n",
    "# Display the graph\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.strategies import BacktestManager\n",
    "\n",
    "bt = BacktestManager.from_universe(start=\"2010-1-1\", commission=10, shares_frac=0)\n",
    "bt.Momentum()\n",
    "bt.values.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e24c49cb70330bda4278cf1d73522e240c5ff00972b9664bed3bfe636b47b7ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
